{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Political Community Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from psaw import PushshiftAPI\n",
    "from urllib.parse import urlparse\n",
    "import tldextract\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='JgYmAnPps7utGg',\n",
    "                     client_secret='g2s1IJiQPnAXSfxua-MFxTSz1xs',\n",
    "                     user_agent='15388throwaway')\n",
    "api = PushshiftAPI(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "def getTopMonthlyPosts(year, month, subreddit):\n",
    "    e_month = month + 1\n",
    "    e_year = year\n",
    "    if month == 12:\n",
    "        e_month = 1\n",
    "        e_year = year + 1\n",
    "\n",
    "    start_epoch = int(dt.datetime(year, month, 1).timestamp())\n",
    "    end_epoch = int(dt.datetime(e_year, e_month, 1). timestamp())\n",
    "    gen = api.search_submissions(before=end_epoch, after=start_epoch,\n",
    "                                subreddit=subreddit, sort='desc',\n",
    "                                sort_type='score', limit=50)\n",
    "    return list(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method to extract the urls from the list\n",
    "def getUrls(gen):\n",
    "    urls = []\n",
    "    for g in gen:\n",
    "        urls.append(g.url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_domains = ['go']\n",
    "non_news_domains = ['reddit', 'imgur', 'twitter', 'twimg', 'youtube', 'google', 'redd', 'youtu']\n",
    "\n",
    "def parseUrl(fullUrl):\n",
    "    parseObj = tldextract.extract(fullUrl)\n",
    "    if parseObj.domain in non_news_domains:\n",
    "        return \"\"\n",
    "    elif parseObj.domain in invalid_domains:\n",
    "        return parseObj.subdomain\n",
    "    return parseObj.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBiases(filename):\n",
    "    least = open(filename, \"r\").read()\n",
    "    soup = BeautifulSoup(least, 'html.parser')\n",
    "    \n",
    "    sources = set()\n",
    "    #websites = set()\n",
    "    for s in soup.findAll('td', ):\n",
    "        source = s.string\n",
    "        if source is not None:\n",
    "            if source[-1] == \")\":\n",
    "                left_paren = source.find('(')\n",
    "                sources.add(source[0:left_paren - 1])\n",
    "                sources.add(parseUrl(source[left_paren + 1:-1]))\n",
    "            else:\n",
    "                sources.add(source)\n",
    "    return sources\n",
    "\n",
    "# Loading the biases to a dict mapping (source/website to bias ranking)\n",
    "left = loadBiases(\"Left.htm\")\n",
    "left_center = loadBiases(\"Left-Center.htm\")\n",
    "least = loadBiases(\"Least.htm\")\n",
    "right_center = loadBiases(\"Right-Center.htm\")\n",
    "right = loadBiases(\"Right.htm\")\n",
    "\n",
    "biases = {}\n",
    "\n",
    "biases.update(biases.fromkeys(left, -2))\n",
    "biases.update(biases.fromkeys(left_center, -1))\n",
    "biases.update(biases.fromkeys(least, 0))\n",
    "biases.update(biases.fromkeys(right_center, 1))\n",
    "biases.update(biases.fromkeys(right, 2))\n",
    "\n",
    "del biases[\"\"]\n",
    "\n",
    "addenum_to_biases = {\"huffpost\" : -2, \n",
    "                     \"buzzfeednews\" : -1, \n",
    "                     \"breitbart\" : 3, \n",
    "                     \"progressivestoday\" : 3, \n",
    "                     \"frontpagemag\" : 3,\n",
    "                     \"dailymail\" : 2,\n",
    "                     \"ap\" : 0,\n",
    "                     \"sputniknews\" : 2,\n",
    "                     \"truthinmedia\" : 3,\n",
    "                     \"resistancereport\" : -3,\n",
    "                     \"redstate\" : 2,\n",
    "                     \"newcenturytimes\" : -3,\n",
    "                     \"rare\" : 1,\n",
    "                     \"rt\" : 1,\n",
    "                     \"americanthinker\" : 3,\n",
    "                     \"cnsnews\" : 3\n",
    "                    }\n",
    "\n",
    "biases.update(addenum_to_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 1 (-47, 50)\n",
      "speaker, https://www.speaker.gov/newsroom/21519-3/\n",
      "2019 2 (-42, 49)\n",
      "nbcsandiego, https://www.nbcsandiego.com/investigations/Source-Leaked-Documents-Show-the-US-Government-Tracking-Journalists-and-Advocates-Through-a-Secret-Database-506783231.html\n",
      "2019 3 (-34, 49)\n",
      "nybooks, https://www.nybooks.com/daily/2019/04/26/mueller-prosecutors-trump-did-obstruct-justice/\n",
      "mystateline, https://www.mystateline.com/news/illinois-democrats-to-trump-show-tax-returns-or-be-barred-from-2020-ballot/1919139230\n",
      "2019 4 (-46, 48)\n",
      "justice, https://www.justice.gov/usao-sdny/pr/bank-ceo-stephen-m-calk-charged-corruptly-soliciting-presidential-administration\n",
      "2019 5 (-28, 49)\n",
      "2019 6 (-44, 50)\n",
      "wnky, https://www.wnky.com/putins-mitch-billboard-grabs-attention-on-interstate-65/\n",
      "2019 7 (-34, 49)\n",
      "clarionledger, https://www.clarionledger.com/story/news/politics/2019/08/27/voting-machine-problems-video-changing-vote-bill-waller-tate-reeves-ms-election-governor-runoff/2129515001/?fbclid=IwAR2RFlFrTu--MwFHtj-UNyEOeIGE4H4DQdzbbyEpIkPoC-wnIp822XkLvUc\n",
      "abc7ny, https://abc7ny.com/politics/petition-rename-portion-of-5th-ave-near-trump-tower-after-obama/5467121/\n",
      "2019 8 (-44, 48)\n",
      "boston, https://www.boston.com/news/local-news/2019/09/15/elizabeth-warren-urges-voters-to-think-beyond-just-defeating-donald-trump\n",
      "2019 9 (-35, 49)\n",
      "boston, https://www.boston.com/news/politics/2019/10/03/elizabeth-warrens-bernie-sanders-heart-procedure/\n",
      "wusa9, https://www.wusa9.com/article/news/local/dc/president-trump-wont-pay-for-minneapolis-rally-still-owes-dc-9million/65-012b6e66-8942-44fb-b4a1-6229b69afe18\n",
      "2019 10 (-28, 48)\n",
      "lex18, https://www.lex18.com/news/decision-2019/beshear-overcomes-trump-effect-to-beat-bevin-to-become-next-ky-governor\n",
      "wjla, https://wjla.com/news/local/nationals-sean-doolittle-white-house\n",
      "2019 11 (-56, 48)\n",
      "cbs8, https://www.cbs8.com/article/news/local/change-of-plea-hearing-set-for-rep-duncan-hunter/509-6dc00285-0aad-435a-ac32-242ed592d3e4\n",
      "eand, https://eand.co/the-economys-not-booming-predatory-capitalism-s-eating-itself-a1663d94498e\n",
      "pressfreedomtracker, https://pressfreedomtracker.us/all-incidents/congressman-nunes-alleges-cnn-daily-beast-committed-crimes-in-reporting-says-will-sue/\n",
      "home-decor-ideas, http://www.home-decor-ideas.info/keep-the-air-inside-your-home-clean-by-using-air-purifier/\n",
      "politicaltribune, https://politicaltribune.org/fox-news-cuts-trump-off-air-after-he-blatantly-lies-about-his-border-wall/\n",
      "infowars, https://www.infowars.com/where-are-the-other-7-terrorists-jailed-with-london-bridge-knifeman/\n",
      "2019 12 (-13, 44)\n"
     ]
    }
   ],
   "source": [
    "def getMonthlyBias(year, month, subreddit):\n",
    "    topMonthlyPostsTest = getTopMonthlyPosts(year,month, subreddit)\n",
    "    topMonthlyPostsUrls = getUrls(topMonthlyPostsTest)\n",
    "    total = 0\n",
    "    total_num_parseable = 0\n",
    "\n",
    "    for url in topMonthlyPostsUrls:\n",
    "        parsed_url = parseUrl(url)\n",
    "        total_num_parseable += 1\n",
    "        if parsed_url != \"\":\n",
    "            if parsed_url in biases:\n",
    "                total += biases.get(parsed_url)\n",
    "            else:\n",
    "                total_num_parseable -= 1\n",
    "                print(parsed_url + \", \" + url)\n",
    "    return (total, total_num_parseable)\n",
    "\n",
    "def getAllMonthlyBiasesSince(year, subreddit):\n",
    "    for i in range(2019 - year + 1):\n",
    "        for month in range(12):\n",
    "            print(year + i, month + 1, getMonthlyBias(year + i, month + 1, subreddit))\n",
    "\n",
    "getAllMonthlyBiasesSince(2019, \"politics\")\n",
    "#getAllMonthlyBiasesSince(2019, \"Conservative\")\n",
    "#getAllMonthlyBiasesSince(2019, \"Liberal\")\n",
    "#getAllMonthlyBiasesSince(2019, \"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
