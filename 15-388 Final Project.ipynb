{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Political Community Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from psaw import PushshiftAPI\n",
    "from urllib.parse import urlparse\n",
    "import tldextract\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='JgYmAnPps7utGg',\n",
    "                     client_secret='g2s1IJiQPnAXSfxua-MFxTSz1xs',\n",
    "                     user_agent='15388throwaway')\n",
    "api = PushshiftAPI(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "def getTopMonthlyPosts(year, month, subreddit):\n",
    "    e_month = month + 1\n",
    "    e_year = year\n",
    "    if month == 12:\n",
    "        e_month = 1\n",
    "        e_year = year + 1\n",
    "\n",
    "    start_epoch = int(dt.datetime(year, month, 1).timestamp())\n",
    "    end_epoch = int(dt.datetime(e_year, e_month, 1). timestamp())\n",
    "    gen = api.search_submissions(before=end_epoch, after=start_epoch,\n",
    "                                subreddit=subreddit, sort='desc',\n",
    "                                sort_type='score', limit=50)\n",
    "    return list(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method to extract the urls from the list\n",
    "def getUrls(gen):\n",
    "    urls = []\n",
    "    for g in gen:\n",
    "        urls.append(g.url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_domains = ['go']\n",
    "non_news_domains = ['reddit', 'imgur', 'twitter', 'twimg', 'youtube', 'google', 'redd', 'youtu']\n",
    "\n",
    "def parseUrl(fullUrl):\n",
    "    parseObj = tldextract.extract(fullUrl)\n",
    "    if parseObj.domain in non_news_domains:\n",
    "        return \"\"\n",
    "    elif parseObj.domain in invalid_domains:\n",
    "        return parseObj.subdomain\n",
    "    return parseObj.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBiases(filename):\n",
    "    least = open(filename, \"r\").read()\n",
    "    soup = BeautifulSoup(least, 'html.parser')\n",
    "    \n",
    "    sources = set()\n",
    "    #websites = set()\n",
    "    for s in soup.findAll('td', ):\n",
    "        source = s.string\n",
    "        if source is not None:\n",
    "            if source[-1] == \")\":\n",
    "                left_paren = source.find('(')\n",
    "                sources.add(source[0:left_paren - 1])\n",
    "                sources.add(parseUrl(source[left_paren + 1:-1]))\n",
    "            else:\n",
    "                sources.add(source)\n",
    "    return sources\n",
    "\n",
    "# Loading the biases to a dict mapping (source/website to bias ranking)\n",
    "left = loadBiases(\"Left.htm\")\n",
    "left_center = loadBiases(\"Left-Center.htm\")\n",
    "least = loadBiases(\"Least.htm\")\n",
    "right_center = loadBiases(\"Right-Center.htm\")\n",
    "right = loadBiases(\"Right.htm\")\n",
    "\n",
    "biases = {}\n",
    "\n",
    "biases.update(biases.fromkeys(left, -2))\n",
    "biases.update(biases.fromkeys(left_center, -1))\n",
    "biases.update(biases.fromkeys(least, 0))\n",
    "biases.update(biases.fromkeys(right_center, 1))\n",
    "biases.update(biases.fromkeys(right, 2))\n",
    "\n",
    "del biases[\"\"]\n",
    "\n",
    "addenum_to_biases = {\"huffpost\" : -2, \n",
    "                     \"buzzfeednews\" : -1, \n",
    "                     \"breitbart\" : 3, \n",
    "                     \"progressivestoday\" : 3, \n",
    "                     \"frontpagemag\" : 3,\n",
    "                     \"dailymail\" : 2,\n",
    "                     \"ap\" : 0,\n",
    "                     \"sputniknews\" : 2,\n",
    "                     \"truthinmedia\" : 3,\n",
    "                     \"resistancereport\" : -3,\n",
    "                     \"redstate\" : 2,\n",
    "                     \"newcenturytimes\" : -3,\n",
    "                     \"rare\" : 1,\n",
    "                     \"rt\" : 1,\n",
    "                     \"americanthinker\" : 3,\n",
    "                     \"cnsnews\" : 3\n",
    "                    }\n",
    "\n",
    "biases.update(addenum_to_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getMonthlyBias(year, month, subreddit):\n",
    "    topMonthlyPostsTest = getTopMonthlyPosts(year, month, subreddit)\n",
    "    topMonthlyPostsUrls = getUrls(topMonthlyPostsTest)\n",
    "    total = 0\n",
    "    total_num_parseable = 0\n",
    "    breakdown = {}\n",
    "    breakdown.update(breakdown.fromkeys([-3, -2, -1, 0, 1, 2, 3], 0))\n",
    "\n",
    "    out_sources = []\n",
    "    \n",
    "    for url in topMonthlyPostsUrls:\n",
    "        parsed_url = parseUrl(url)\n",
    "        total_num_parseable += 1\n",
    "        if parsed_url != \"\":\n",
    "            if parsed_url in biases:\n",
    "                bias = biases.get(parsed_url)\n",
    "                total += bias\n",
    "                breakdown[bias] += 1\n",
    "                out_sources.append(parsed_url)\n",
    "            else:\n",
    "                total_num_parseable -= 1\n",
    "                #print(parsed_url + \", \" + url)\n",
    "    return (total, total_num_parseable, breakdown, out_sources)\n",
    "\n",
    "def getAllMonthlyBiasesSince(year, subreddit):\n",
    "    years = []\n",
    "    months = []\n",
    "    totals = []\n",
    "    parseables = []\n",
    "    breakdowns = []\n",
    "    out_sources_overall = []\n",
    "    for i in range(2019 - year + 1):\n",
    "        for month in range(12):\n",
    "            #print(year + i, month + 1, getMonthlyBias(year + i, month + 1, subreddit))\n",
    "            (total, parseable, breakdown, out_s) = getMonthlyBias(year + i, month + 1, subreddit)\n",
    "            years.append(year+i)\n",
    "            months.append(month+1)\n",
    "            totals.append(total)\n",
    "            parseables.append(parseable)\n",
    "            breakdowns.append(breakdown)\n",
    "            out_sources_overall += out_s\n",
    "    return (years, months, totals, parseables, breakdowns, out_sources_overall)\n",
    "\n",
    "(y_politics, m_politics, tot_politics, num_politics, b_politics, os_politics) = getAllMonthlyBiasesSince(2016, \"politics\")\n",
    "(_, _, tot_Conservative, num_Conservative, b_Conservative, os_Conservative) = getAllMonthlyBiasesSince(2016, \"Conservative\")\n",
    "(_, _, tot_Liberal, num_Liberal, b_Liberal, os_Liberal) = getAllMonthlyBiasesSince(2016, \"Liberal\")\n",
    "(_, _, tot_moderatepolitics, num_moderatepolitics, b_moderatepolitics, os_moderatepolitics) = getAllMonthlyBiasesSince(2016, \"moderatepolitics\")\n",
    "(_, _, tot_news, num_news, b_news, os_news) = getAllMonthlyBiasesSince(2016, \"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "48\n",
      "48\n",
      "48\n",
      "48\n",
      "48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x145715358>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_month = []\n",
    "\n",
    "for k in range(len(y_politics)):\n",
    "    m_str = str(m_politics[k])\n",
    "    if m_politics[k] < 10:\n",
    "        m_str = \"0\" + m_str\n",
    "    year_month.append(str(y_politics[k]) + \"-\" + m_str)\n",
    "\n",
    "dates = np.array(year_month, dtype='datetime64')\n",
    "politics_score = np.divide(np.array(tot_politics), np.array(num_politics))\n",
    "conservative_score = np.divide(np.array(tot_Conservative), np.array(num_Conservative))\n",
    "liberal_score = np.divide(np.array(tot_Liberal), np.array(num_Liberal))\n",
    "moderatepolitics_score = np.divide(np.array(tot_moderatepolitics), np.array(num_moderatepolitics))\n",
    "news_score = np.divide(np.array(tot_news), np.array(num_news))\n",
    "print(len(politics_score))\n",
    "print(len(conservative_score))\n",
    "print(len(liberal_score))\n",
    "print(len(moderatepolitics_score))\n",
    "print(len(news_score))\n",
    "print(len(dates))\n",
    "df_all_subreddits = pd.DataFrame({ 'dates' : dates, 'politics' : politics_score, 'conservative' : conservative_score,\n",
    "                            'liberal' : liberal_score, 'moderatepolitics' : moderatepolitics_score,\n",
    "                            'news' : news_score})\n",
    "#%matplotlib \n",
    "fig=plt.figure(figsize=(18, 16), dpi= 160, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot('dates', 'politics', data=df_all_subreddits)\n",
    "plt.plot('dates', 'conservative', data=df_all_subreddits)\n",
    "plt.plot('dates', 'liberal', data=df_all_subreddits)\n",
    "plt.plot('dates', 'moderatepolitics', data=df_all_subreddits)\n",
    "plt.plot('dates', 'news', data=df_all_subreddits)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1163ba160>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_test = np.ndarray((48, 7), int)\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "for index in range(len(b_politics)):\n",
    "    for i in range(7):\n",
    "        pol_test[index][i] = (b_politics[index])[i - 3]\n",
    "\n",
    "pol_test = pol_test.T\n",
    "#plt.plot(dates, pol_test[0], label=\"very left\")\n",
    "plt.plot(dates, pol_test[1], label=\"left\")\n",
    "plt.plot(dates, pol_test[2], label=\"left-center\")\n",
    "plt.plot(dates, pol_test[3], label=\"neutral\")\n",
    "plt.plot(dates, pol_test[4], label=\"right-center\")\n",
    "plt.plot(dates, pol_test[5], label=\"right\")\n",
    "#plt.plot(dates, pol_test[6], label=\"very right\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dailywire': 87, 'foxnews': 74, 'breitbart': 55, 'dailycaller': 43, 'townhall': 27, 'thehill': 27, 'nypost': 26, 'washingtonexaminer': 22, 'redstate': 20, 'washingtontimes': 19}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "w = dict(Counter(os_Conservative).most_common(10))\n",
    "print(w)\n",
    "plt.xticks(rotation=60)\n",
    "\n",
    "plt.bar(*zip(*w.items()))\n",
    "#plt.bar(range(len(w.keys())), w.values, align='center')\n",
    "#plt.xticks(range(len(w.keys()), list(w.keys())))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Counter(os_Conservative).most_common()\n",
    "#Counter(os_Liberal).most_common()\n",
    "#Counter(os_moderatepolitics).most_common()\n",
    "#Counter(os_news).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
